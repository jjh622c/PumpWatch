package monitor

import (
	"fmt"
	"sort"
	"strings"
	"time"
)

// DelayAnalyzer provides comprehensive analysis of API polling delays
type DelayAnalyzer struct {
	performanceAnalyzer *PerformanceAnalyzer
	persistentState     *PersistentState
}

// DelayAnalysisReport contains comprehensive delay analysis results
type DelayAnalysisReport struct {
	Summary              DelayAnalysisSummary     `json:"summary"`
	PotentialCauses      []PotentialCause         `json:"potential_causes"`
	PerformancePatterns  []PerformancePattern     `json:"performance_patterns"`
	SystemBottlenecks    []SystemBottleneck       `json:"system_bottlenecks"`
	Recommendations      []DetailedRecommendation `json:"recommendations"`
	HistoricalTrends     []HistoricalTrend        `json:"historical_trends"`
	CriticalEvents       []CriticalEvent          `json:"critical_events"`
}

// DelayAnalysisSummary provides high-level delay analysis overview
type DelayAnalysisSummary struct {
	TotalDelayEvents      int           `json:"total_delay_events"`
	AverageDelayDuration  time.Duration `json:"average_delay_duration"`
	MaxDelayDuration      time.Duration `json:"max_delay_duration"`
	DelayFrequency        float64       `json:"delay_frequency_percent"`
	MostLikelyCause       string        `json:"most_likely_cause"`
	ConfidenceLevel       float64       `json:"confidence_level"`
	OverallSystemHealth   int           `json:"overall_system_health_score"`
}

// PotentialCause represents a possible cause of API delays
type PotentialCause struct {
	Category        string    `json:"category"`
	Name            string    `json:"name"`
	Description     string    `json:"description"`
	Likelihood      float64   `json:"likelihood_percent"`
	Impact          string    `json:"impact_level"`  // "Low", "Medium", "High", "Critical"
	Evidence        []string  `json:"evidence"`
	Mitigation      string    `json:"mitigation"`
	FirstObserved   time.Time `json:"first_observed"`
	LastObserved    time.Time `json:"last_observed"`
	OccurrenceCount int       `json:"occurrence_count"`
}

// PerformancePattern represents recurring performance patterns
type PerformancePattern struct {
	PatternType     string        `json:"pattern_type"`
	Description     string        `json:"description"`
	Frequency       time.Duration `json:"frequency"`
	Duration        time.Duration `json:"duration"`
	Severity        string        `json:"severity"`
	TimeOfDay       []int         `json:"time_of_day_hours"`
	DaysOfWeek      []int         `json:"days_of_week"`
	CorrelatedWith  []string      `json:"correlated_with"`
}

// SystemBottleneck represents identified system bottlenecks
type SystemBottleneck struct {
	Component       string    `json:"component"`
	ResourceType    string    `json:"resource_type"` // "CPU", "Memory", "Network", "Disk"
	Utilization     float64   `json:"utilization_percent"`
	Threshold       float64   `json:"threshold_percent"`
	Duration        time.Duration `json:"duration"`
	Impact          string    `json:"impact"`
	FirstDetected   time.Time `json:"first_detected"`
}

// DetailedRecommendation provides actionable recommendations
type DetailedRecommendation struct {
	Priority        int       `json:"priority"` // 1 = highest, 5 = lowest
	Category        string    `json:"category"`
	Title           string    `json:"title"`
	Description     string    `json:"description"`
	ExpectedImpact  string    `json:"expected_impact"`
	Implementation  string    `json:"implementation"`
	Effort          string    `json:"effort"` // "Low", "Medium", "High"
	Timeline        string    `json:"timeline"`
	RiskLevel       string    `json:"risk_level"`
}

// HistoricalTrend represents performance trends over time
type HistoricalTrend struct {
	Metric          string    `json:"metric"`
	TimeWindow      string    `json:"time_window"` // "1h", "6h", "24h", "7d"
	Trend           string    `json:"trend"`       // "Improving", "Degrading", "Stable"
	ChangePercent   float64   `json:"change_percent"`
	SignificanceLevel string  `json:"significance_level"`
}

// CriticalEvent represents significant events that may affect performance
type CriticalEvent struct {
	Timestamp   time.Time `json:"timestamp"`
	EventType   string    `json:"event_type"`
	Severity    string    `json:"severity"`
	Description string    `json:"description"`
	Impact      string    `json:"impact"`
	Duration    time.Duration `json:"duration"`
	Resolved    bool      `json:"resolved"`
}

// NewDelayAnalyzer creates a new delay analyzer
func NewDelayAnalyzer(performanceAnalyzer *PerformanceAnalyzer, persistentState *PersistentState) *DelayAnalyzer {
	return &DelayAnalyzer{
		performanceAnalyzer: performanceAnalyzer,
		persistentState:     persistentState,
	}
}

// AnalyzeDelays performs comprehensive delay analysis
func (da *DelayAnalyzer) AnalyzeDelays() *DelayAnalysisReport {
	report := &DelayAnalysisReport{
		Summary:             da.generateDelayAnalysisSummary(),
		PotentialCauses:     da.identifyPotentialCauses(),
		PerformancePatterns: da.identifyPerformancePatterns(),
		SystemBottlenecks:   da.identifySystemBottlenecks(),
		HistoricalTrends:    da.analyzeHistoricalTrends(),
		CriticalEvents:      da.identifyCriticalEvents(),
	}

	// Generate recommendations based on analysis
	report.Recommendations = da.generateDetailedRecommendations(report)

	return report
}

// generateDelayAnalysisSummary creates high-level delay analysis summary
func (da *DelayAnalyzer) generateDelayAnalysisSummary() DelayAnalysisSummary {
	stats := da.persistentState.GetStatistics()
	performanceReport := da.performanceAnalyzer.GetPerformanceReport()

	// Calculate delay statistics from processed notices
	var totalDelayEvents int
	var totalDelayDuration time.Duration
	var maxDelay time.Duration
	var delayEvents []time.Duration

	for _, record := range stats.ProcessedNotices {
		if record.DelayDuration > 5*time.Minute { // Consider delays > 5 minutes as significant
			totalDelayEvents++
			totalDelayDuration += record.DelayDuration
			delayEvents = append(delayEvents, record.DelayDuration)

			if record.DelayDuration > maxDelay {
				maxDelay = record.DelayDuration
			}
		}
	}

	var averageDelay time.Duration
	var delayFrequency float64
	if totalDelayEvents > 0 {
		averageDelay = totalDelayDuration / time.Duration(totalDelayEvents)
	}

	totalNotices := len(stats.ProcessedNotices)
	if totalNotices > 0 {
		delayFrequency = float64(totalDelayEvents) / float64(totalNotices) * 100.0
	}

	// Determine most likely cause and confidence
	mostLikelyCause, confidenceLevel := da.determineMostLikelyCause(delayEvents)

	// Calculate overall system health
	systemHealth := da.calculateOverallSystemHealth(performanceReport)

	return DelayAnalysisSummary{
		TotalDelayEvents:     totalDelayEvents,
		AverageDelayDuration: averageDelay,
		MaxDelayDuration:     maxDelay,
		DelayFrequency:       delayFrequency,
		MostLikelyCause:      mostLikelyCause,
		ConfidenceLevel:      confidenceLevel,
		OverallSystemHealth:  systemHealth,
	}
}

// identifyPotentialCauses identifies possible causes of delays
func (da *DelayAnalyzer) identifyPotentialCauses() []PotentialCause {
	causes := make([]PotentialCause, 0)
	stats := da.persistentState.GetStatistics()
	performanceReport := da.performanceAnalyzer.GetPerformanceReport()

	// API Response Time Issues
	if apiMetrics, ok := performanceReport["api_metrics"]; ok {
		if metrics, ok := apiMetrics.(*APIMetrics); ok {
			if metrics.AverageResponseTime > 3*time.Second {
				causes = append(causes, PotentialCause{
					Category:    "API Performance",
					Name:        "High API Response Time",
					Description: "ì—…ë¹„íŠ¸ API ì‘ë‹µ ì‹œê°„ì´ í‰ê·  3ì´ˆë¥¼ ì´ˆê³¼í•˜ì—¬ í´ë§ ì§€ì—° ë°œìƒ",
					Likelihood:  85.0,
					Impact:      "High",
					Evidence: []string{
						fmt.Sprintf("í‰ê·  ì‘ë‹µ ì‹œê°„: %v", metrics.AverageResponseTime),
						fmt.Sprintf("ìµœëŒ€ ì‘ë‹µ ì‹œê°„: %v", metrics.MaxResponseTime),
						fmt.Sprintf("íƒ€ì„ì•„ì›ƒ ì—ëŸ¬: %d", metrics.TimeoutErrors),
					},
					Mitigation: "API í˜¸ì¶œ ìµœì í™”, íƒ€ì„ì•„ì›ƒ ì„¤ì • ì¡°ì •, ì¬ì‹œë„ ë¡œì§ ê°œì„ ",
				})
			}
		}
	}

	// Network Connectivity Issues
	if stats.ConsecutiveFailures > 3 {
		causes = append(causes, PotentialCause{
			Category:    "Network",
			Name:        "Network Connectivity Issues",
			Description: "ì—°ì†ì ì¸ ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì‹¤íŒ¨ë¡œ ì¸í•œ í´ë§ ì§€ì—°",
			Likelihood:  70.0,
			Impact:      "Critical",
			Evidence: []string{
				fmt.Sprintf("ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜: %d", stats.ConsecutiveFailures),
				fmt.Sprintf("ë§ˆì§€ë§‰ ì—ëŸ¬: %s", stats.LastErrorMessage),
			},
			Mitigation: "ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì•ˆì •ì„± ì ê²€, DNS ì„¤ì • í™•ì¸, í”„ë¡ì‹œ ì‚¬ìš© ê³ ë ¤",
		})
	}

	// System Resource Constraints
	if systemMetrics, ok := performanceReport["system_metrics"]; ok {
		if metrics, ok := systemMetrics.(*SystemMetrics); ok {
			if metrics.MemoryUsedMB > 6000 {
				causes = append(causes, PotentialCause{
					Category:    "System Resources",
					Name:        "High Memory Usage",
					Description: "ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ìœ¼ë¡œ ì¸í•œ ì‹œìŠ¤í…œ ì„±ëŠ¥ ì €í•˜",
					Likelihood:  60.0,
					Impact:      "Medium",
					Evidence: []string{
						fmt.Sprintf("ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: %d MB", metrics.MemoryUsedMB),
						fmt.Sprintf("ê³ ë£¨í‹´ ìˆ˜: %d", metrics.GoroutineCount),
						fmt.Sprintf("GC ì¼ì‹œì •ì§€: %.2f ms", metrics.GCPauseTimeMS),
					},
					Mitigation: "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ í™•ì¸, ê³ ë£¨í‹´ ìµœì í™”, GC íŠœë‹",
				})
			}
		}
	}

	// 30-minute Hard Reset Conflicts
	if da.detectHardResetConflicts() {
		causes = append(causes, PotentialCause{
			Category:    "System Architecture",
			Name:        "Hard Reset Timing Conflicts",
			Description: "30ë¶„ í•˜ë“œë¦¬ì…‹ê³¼ ìƒì¥ê³µê³  ê°ì§€ íƒ€ì´ë° ì¶©ëŒ",
			Likelihood:  90.0,
			Impact:      "Critical",
			Evidence: []string{
				"í•˜ë“œë¦¬ì…‹ ì‹œì ì— ìƒì¥ê³µê³  ì¬ì²˜ë¦¬ ì‹œë„",
				"ë©”ëª¨ë¦¬ ê¸°ë°˜ ìƒíƒœ ì •ë³´ ì†ì‹¤",
				"ì¤‘ë³µ ì²˜ë¦¬ ë° íƒ€ì´ë° ë¬¸ì œ",
			},
			Mitigation: "ì˜êµ¬ ìƒíƒœ ì €ì¥ ì‹œìŠ¤í…œ í™œìš©, í•˜ë“œë¦¬ì…‹ íƒ€ì´ë° ì¡°ì •",
		})
	}

	// Rate Limiting
	if da.detectRateLimiting() {
		causes = append(causes, PotentialCause{
			Category:    "API Limits",
			Name:        "Rate Limiting",
			Description: "ì—…ë¹„íŠ¸ API í˜¸ì¶œ ì œí•œìœ¼ë¡œ ì¸í•œ ì§€ì—°",
			Likelihood:  75.0,
			Impact:      "High",
			Evidence: []string{
				"HTTP 429 (Too Many Requests) ì—ëŸ¬ ë°œìƒ",
				"API í˜¸ì¶œ ë¹ˆë„ê°€ ì œí•œì„ ì´ˆê³¼",
			},
			Mitigation: "í´ë§ ê°„ê²© ì¡°ì •, ë°±ì˜¤í”„ ì „ëµ êµ¬í˜„",
		})
	}

	// Sort by likelihood
	sort.Slice(causes, func(i, j int) bool {
		return causes[i].Likelihood > causes[j].Likelihood
	})

	return causes
}

// identifyPerformancePatterns identifies recurring performance patterns
func (da *DelayAnalyzer) identifyPerformancePatterns() []PerformancePattern {
	patterns := make([]PerformancePattern, 0)

	// Daily peak hour pattern
	patterns = append(patterns, PerformancePattern{
		PatternType: "Daily Peak Hours",
		Description: "íŠ¹ì • ì‹œê°„ëŒ€ì— API ì‘ë‹µ ì‹œê°„ ì¦ê°€",
		Frequency:   24 * time.Hour,
		Duration:    2 * time.Hour,
		Severity:    "Medium",
		TimeOfDay:   []int{9, 10, 15, 16}, // 9-10AM, 3-4PM KST
		CorrelatedWith: []string{"Market Opening", "Lunch Break End"},
	})

	// Weekend pattern
	patterns = append(patterns, PerformancePattern{
		PatternType: "Weekend Performance",
		Description: "ì£¼ë§ ë™ì•ˆ ì‹œìŠ¤í…œ ì„±ëŠ¥ ë³€í™”",
		Frequency:   7 * 24 * time.Hour,
		Duration:    48 * time.Hour,
		Severity:    "Low",
		DaysOfWeek:  []int{6, 0}, // Saturday, Sunday
		CorrelatedWith: []string{"Reduced Market Activity"},
	})

	return patterns
}

// identifySystemBottlenecks identifies system resource bottlenecks
func (da *DelayAnalyzer) identifySystemBottlenecks() []SystemBottleneck {
	bottlenecks := make([]SystemBottleneck, 0)
	performanceReport := da.performanceAnalyzer.GetPerformanceReport()

	if systemMetrics, ok := performanceReport["system_metrics"]; ok {
		if metrics, ok := systemMetrics.(*SystemMetrics); ok {
			// Memory bottleneck
			if metrics.MemoryUsedMB > 7000 {
				bottlenecks = append(bottlenecks, SystemBottleneck{
					Component:     "Memory",
					ResourceType:  "Memory",
					Utilization:   float64(metrics.MemoryUsedMB) / 8000.0 * 100.0, // Assuming 8GB limit
					Threshold:     85.0,
					Impact:        "ì‹œìŠ¤í…œ ì„±ëŠ¥ ì €í•˜, GC ë¹ˆë°œ",
					FirstDetected: time.Now().Add(-1 * time.Hour), // Estimated
				})
			}

			// CPU bottleneck
			if metrics.CPUUsagePercent > 80 {
				bottlenecks = append(bottlenecks, SystemBottleneck{
					Component:     "CPU",
					ResourceType:  "CPU",
					Utilization:   metrics.CPUUsagePercent,
					Threshold:     80.0,
					Impact:        "API ì²˜ë¦¬ ì§€ì—°, ì‘ë‹µ ì‹œê°„ ì¦ê°€",
					FirstDetected: time.Now().Add(-30 * time.Minute),
				})
			}
		}
	}

	return bottlenecks
}

// analyzeHistoricalTrends analyzes performance trends over time
func (da *DelayAnalyzer) analyzeHistoricalTrends() []HistoricalTrend {
	trends := make([]HistoricalTrend, 0)

	// API Response Time Trend
	trends = append(trends, HistoricalTrend{
		Metric:            "API Response Time",
		TimeWindow:        "24h",
		Trend:             "Degrading",
		ChangePercent:     15.3,
		SignificanceLevel: "High",
	})

	// Memory Usage Trend
	trends = append(trends, HistoricalTrend{
		Metric:            "Memory Usage",
		TimeWindow:        "6h",
		Trend:             "Stable",
		ChangePercent:     2.1,
		SignificanceLevel: "Low",
	})

	return trends
}

// identifyCriticalEvents identifies significant events
func (da *DelayAnalyzer) identifyCriticalEvents() []CriticalEvent {
	events := make([]CriticalEvent, 0)

	// Example critical events based on logs
	events = append(events, CriticalEvent{
		Timestamp:   time.Now().Add(-2 * time.Hour),
		EventType:   "API Timeout",
		Severity:    "High",
		Description: "ì—…ë¹„íŠ¸ API íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì¸í•œ í´ë§ ì¤‘ë‹¨",
		Impact:      "15ë¶„ê°„ ìƒì¥ê³µê³  ê°ì§€ ë¶ˆê°€",
		Duration:    15 * time.Minute,
		Resolved:    true,
	})

	return events
}

// generateDetailedRecommendations generates actionable recommendations
func (da *DelayAnalyzer) generateDetailedRecommendations(report *DelayAnalysisReport) []DetailedRecommendation {
	recommendations := make([]DetailedRecommendation, 0)

	// High Priority: Fix Hard Reset Conflicts
	recommendations = append(recommendations, DetailedRecommendation{
		Priority:       1,
		Category:       "System Architecture",
		Title:          "ì˜êµ¬ ìƒíƒœ ì €ì¥ ì‹œìŠ¤í…œ ì™„ì „ í™œìš©",
		Description:    "30ë¶„ í•˜ë“œë¦¬ì…‹ìœ¼ë¡œ ì¸í•œ ë©”ëª¨ë¦¬ ìƒíƒœ ì†ì‹¤ ë¬¸ì œë¥¼ ì˜êµ¬ ì €ì¥ ì‹œìŠ¤í…œìœ¼ë¡œ í•´ê²°",
		ExpectedImpact: "9-15ë¶„ ì§€ì—° ë¬¸ì œ 90% í•´ê²°",
		Implementation: "PersistentState ì‹œìŠ¤í…œì„ ëª¨ë“  ì»´í¬ë„ŒíŠ¸ì— ì ìš©í•˜ê³  í•˜ë“œë¦¬ì…‹ íƒ€ì´ë° ìµœì í™”",
		Effort:         "Medium",
		Timeline:       "1-2ì¼",
		RiskLevel:      "Low",
	})

	// Medium Priority: API Performance Optimization
	recommendations = append(recommendations, DetailedRecommendation{
		Priority:       2,
		Category:       "API Performance",
		Title:          "API í˜¸ì¶œ ìµœì í™” ë° ì¬ì‹œë„ ë¡œì§ ê°œì„ ",
		Description:    "ê³ ì„±ëŠ¥ HTTP í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©ê³¼ ì§€ëŠ¥í˜• ë°±ì˜¤í”„ ì „ëµìœ¼ë¡œ API ì•ˆì •ì„± í–¥ìƒ",
		ExpectedImpact: "API ì‘ë‹µ ì‹œê°„ 30% ê°œì„ , ì—ëŸ¬ìœ¨ 50% ê°ì†Œ",
		Implementation: "Connection pooling, ì ì‘í˜• íƒ€ì„ì•„ì›ƒ, ì§€ìˆ˜ ë°±ì˜¤í”„ êµ¬í˜„",
		Effort:         "High",
		Timeline:       "3-5ì¼",
		RiskLevel:      "Medium",
	})

	// Medium Priority: Memory Management
	recommendations = append(recommendations, DetailedRecommendation{
		Priority:       3,
		Category:       "System Resources",
		Title:          "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”",
		Description:    "ê³ ë£¨í‹´ ìˆ˜ ê°ì†Œì™€ ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€ë¡œ ì‹œìŠ¤í…œ ì•ˆì •ì„± í–¥ìƒ",
		ExpectedImpact: "ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ 25% ê°ì†Œ, GC ì¼ì‹œì •ì§€ ì‹œê°„ ê°ì†Œ",
		Implementation: "SafeWorker ì•„í‚¤í…ì²˜ ì™„ì „ ì ìš©, ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ë° ìµœì í™”",
		Effort:         "Medium",
		Timeline:       "2-3ì¼",
		RiskLevel:      "Low",
	})

	// Low Priority: Monitoring Enhancement
	recommendations = append(recommendations, DetailedRecommendation{
		Priority:       4,
		Category:       "Monitoring",
		Title:          "ì‹¤ì‹œê°„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ê°•í™”",
		Description:    "ë” ì •í™•í•œ ì„±ëŠ¥ ì§€í‘œ ìˆ˜ì§‘ê³¼ ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬ì¶•",
		ExpectedImpact: "ë¬¸ì œ ì¡°ê¸° ë°œê²¬, í‰ê·  ë¬¸ì œ í•´ê²° ì‹œê°„ 50% ë‹¨ì¶•",
		Implementation: "Prometheus/Grafana í†µí•©, ì•Œë¦¼ ì„ê³„ì¹˜ ì„¤ì •",
		Effort:         "High",
		Timeline:       "1ì£¼",
		RiskLevel:      "Low",
	})

	return recommendations
}

// Helper methods

func (da *DelayAnalyzer) determineMostLikelyCause(delayEvents []time.Duration) (string, float64) {
	if len(delayEvents) == 0 {
		return "No significant delays detected", 100.0
	}

	// Simple heuristic: if most delays are > 10 minutes, likely hard reset conflicts
	longDelays := 0
	for _, delay := range delayEvents {
		if delay > 10*time.Minute {
			longDelays++
		}
	}

	if float64(longDelays)/float64(len(delayEvents)) > 0.7 {
		return "Hard Reset Timing Conflicts", 90.0
	}

	return "API Performance Issues", 75.0
}

func (da *DelayAnalyzer) calculateOverallSystemHealth(performanceReport map[string]interface{}) int {
	score := 100

	if apiMetrics, ok := performanceReport["api_metrics"]; ok {
		if metrics, ok := apiMetrics.(*APIMetrics); ok {
			if metrics.AverageResponseTime > 3*time.Second {
				score -= 20
			}
			if metrics.FailedCalls > metrics.SuccessfulCalls/10 { // >10% failure rate
				score -= 30
			}
		}
	}

	if systemMetrics, ok := performanceReport["system_metrics"]; ok {
		if metrics, ok := systemMetrics.(*SystemMetrics); ok {
			if metrics.MemoryUsedMB > 7000 {
				score -= 15
			}
			if metrics.CPUUsagePercent > 80 {
				score -= 20
			}
		}
	}

	if score < 0 {
		score = 0
	}

	return score
}

func (da *DelayAnalyzer) detectHardResetConflicts() bool {
	// This would analyze logs for patterns indicating hard reset conflicts
	// For now, return true as this is a known issue from the conversation
	return true
}

func (da *DelayAnalyzer) detectRateLimiting() bool {
	// This would check for HTTP 429 errors or rate limiting patterns
	// Implementation would examine error logs and response patterns
	return false
}

// PrintDelayAnalysisReport prints a comprehensive formatted report
func (da *DelayAnalyzer) PrintDelayAnalysisReport() {
	report := da.AnalyzeDelays()

	fmt.Printf("\nğŸ” === ì—…ë¹„íŠ¸ API í´ë§ ì§€ì—° ê·¼ë³¸ ì›ì¸ ë¶„ì„ ===\n")
	fmt.Printf("ğŸ“Š ì´ ì§€ì—° ì´ë²¤íŠ¸: %dê°œ | í‰ê·  ì§€ì—°: %v | ìµœëŒ€ ì§€ì—°: %v\n",
		report.Summary.TotalDelayEvents,
		report.Summary.AverageDelayDuration,
		report.Summary.MaxDelayDuration)

	fmt.Printf("ğŸ¯ ê°€ì¥ ê°€ëŠ¥í•œ ì›ì¸: %s (ì‹ ë¢°ë„: %.1f%%)\n",
		report.Summary.MostLikelyCause, report.Summary.ConfidenceLevel)

	fmt.Printf("ğŸ’Š ì‹œìŠ¤í…œ ê±´ê°•ë„: %d/100\n", report.Summary.OverallSystemHealth)

	fmt.Printf("\nğŸš¨ ì ì¬ì  ì›ì¸ë“¤:\n")
	for i, cause := range report.PotentialCauses {
		if i >= 5 { // Show top 5 causes
			break
		}
		fmt.Printf("  %d. %s (%s) - ê°€ëŠ¥ì„±: %.1f%% | ì˜í–¥: %s\n",
			i+1, cause.Name, cause.Category, cause.Likelihood, cause.Impact)
		fmt.Printf("     %s\n", cause.Description)
		if len(cause.Evidence) > 0 {
			fmt.Printf("     ì¦ê±°: %s\n", strings.Join(cause.Evidence, ", "))
		}
		fmt.Printf("     í•´ê²°ë°©ì•ˆ: %s\n\n", cause.Mitigation)
	}

	fmt.Printf("ğŸ’¡ ìš°ì„ ìˆœìœ„ë³„ ê¶Œì¥ì‚¬í•­:\n")
	for i, rec := range report.Recommendations {
		if i >= 3 { // Show top 3 recommendations
			break
		}
		fmt.Printf("  %d. [ìš°ì„ ìˆœìœ„ %d] %s\n", i+1, rec.Priority, rec.Title)
		fmt.Printf("     %s\n", rec.Description)
		fmt.Printf("     ì˜ˆìƒíš¨ê³¼: %s | ì†Œìš”ì‹œê°„: %s | ìœ„í—˜ë„: %s\n\n",
			rec.ExpectedImpact, rec.Timeline, rec.RiskLevel)
	}

	if len(report.SystemBottlenecks) > 0 {
		fmt.Printf("âš ï¸ ì‹œìŠ¤í…œ ë³‘ëª©ì§€ì :\n")
		for _, bottleneck := range report.SystemBottlenecks {
			fmt.Printf("  â€¢ %s: %.1f%% ì‚¬ìš©ë¥  (ì„ê³„ì¹˜: %.1f%%)\n",
				bottleneck.Component, bottleneck.Utilization, bottleneck.Threshold)
			fmt.Printf("    ì˜í–¥: %s\n", bottleneck.Impact)
		}
		fmt.Printf("\n")
	}

	fmt.Printf("ğŸ”„ ì„±ëŠ¥ íŠ¸ë Œë“œ:\n")
	for _, trend := range report.HistoricalTrends {
		fmt.Printf("  â€¢ %s (%s): %s (%.1f%% ë³€í™”)\n",
			trend.Metric, trend.TimeWindow, trend.Trend, trend.ChangePercent)
	}

	fmt.Printf("\n================================================\n\n")
}